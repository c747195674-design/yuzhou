import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import warnings
import os
from matplotlib.font_manager import FontProperties
warnings.filterwarnings('ignore')

# å­—ä½“è®¾ç½®å‡½æ•°
def setup_chinese_font():
    """è®¾ç½®ä¸­æ–‡å­—ä½“"""
    try:
        # å°è¯•åŠ è½½é¡¹ç›®ä¸­çš„å­—ä½“æ–‡ä»¶
        font_path = 'simhei.ttf'  # å­—ä½“æ–‡ä»¶åº”è¯¥åœ¨é¡¹ç›®æ ¹ç›®å½•
        
        if os.path.exists(font_path):
            # ä½¿ç”¨è‡ªå®šä¹‰å­—ä½“
            chinese_font = FontProperties(fname=font_path)
            plt.rcParams['font.family'] = chinese_font.get_name()
            plt.rcParams['axes.unicode_minus'] = False
            return chinese_font
        else:
            # å¦‚æœå­—ä½“æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°è¯•ç³»ç»Ÿå­—ä½“
            plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans', 'Arial Unicode MS', 'WenQuanYi Micro Hei']
            plt.rcParams['axes.unicode_minus'] = False
            return None
    except Exception as e:
        st.warning(f"å­—ä½“åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å­—ä½“: {e}")
        plt.rcParams['font.sans-serif'] = ['DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False
        return None

# è·å–ä¸­æ–‡å­—ä½“å±æ€§
def get_chinese_font_prop():
    """è·å–ä¸­æ–‡å­—ä½“å±æ€§ç”¨äºmatplotlib"""
    font_path = 'simhei.ttf'
    if os.path.exists(font_path):
        return FontProperties(fname=font_path)
    else:
        return FontProperties()

class CarbonEmissionAssessment:
    def __init__(self):
        self.emission_factors = {
            'electricity': 0.6205,
            'natural_gas': 2.162,
            'coal': 2.493,
            'diesel': 2.674,
            'gasoline': 2.296,
            'steam': 0.126,
            'water': 0.91,
        }
        self.time_factors = {
            'equipment_operation': 5.2,
            'transportation': 12.5,
            'labor_indirect': 2.1,
        }
        self.custom_factors = {}
        self.factor_correlations = {}

    def set_custom_factors(self, factors_config):
        self.custom_factors = factors_config
        for factor_name, config in factors_config.items():
            self.factor_correlations[factor_name] = config.get('correlation', 'positive')

    def calculate_coefficient_of_variation_weights(self, data, correlation_settings=None):
        """
        ä½¿ç”¨å˜å¼‚ç³»æ•°æ³•è®¡ç®—æƒé‡ï¼Œé€‚ç”¨äºå°æ ·æœ¬æƒ…å†µ
        """
        data_processed = data.copy()
        
        # å¤„ç†ç›¸å…³æ€§è®¾ç½®
        if correlation_settings:
            for col, correlation in correlation_settings.items():
                if col in data_processed.columns and correlation == 'negative':
                    max_val = data_processed[col].max()
                    min_val = data_processed[col].min()
                    if max_val != min_val:
                        data_processed[col] = max_val + min_val - data_processed[col]
        
        # è®¡ç®—å˜å¼‚ç³»æ•°
        cv_values = []
        for col in data_processed.columns:
            mean_val = data_processed[col].mean()
            std_val = data_processed[col].std()
            if mean_val != 0 and std_val != 0:
                cv = std_val / mean_val
            else:
                cv = 0.01  # é¿å…é™¤é›¶é”™è¯¯
            cv_values.append(abs(cv))
        
        # æ ‡å‡†åŒ–å˜å¼‚ç³»æ•°å¾—åˆ°æƒé‡
        cv_sum = sum(cv_values)
        if cv_sum == 0:
            weights = np.ones(len(cv_values)) / len(cv_values)
        else:
            weights = np.array(cv_values) / cv_sum
        
        return weights, correlation_settings

    def calculate_enhanced_entropy_weights(self, data, correlation_settings=None):
        """
        å¢å¼ºç‰ˆç†µæƒæ³•ï¼Œå¯¹å°æ ·æœ¬è¿›è¡Œç‰¹åˆ«å¤„ç†
        """
        data_processed = data.copy()
        m, n = data_processed.shape
        
        # å¤„ç†ç›¸å…³æ€§è®¾ç½®
        if correlation_settings:
            for col, correlation in correlation_settings.items():
                if col in data_processed.columns and correlation == 'negative':
                    max_val = data_processed[col].max()
                    min_val = data_processed[col].min()
                    if max_val != min_val:
                        data_processed[col] = max_val + min_val - data_processed[col]
        
        # å°æ ·æœ¬ç‰¹åˆ«å¤„ç†
        if m <= 3:
            st.info(f"æ£€æµ‹åˆ°å°æ ·æœ¬æ•°æ®({m}ä¸ªæ ·æœ¬)ï¼Œè‡ªåŠ¨åˆ‡æ¢åˆ°å˜å¼‚ç³»æ•°æ³•è®¡ç®—æƒé‡")
            return self.calculate_coefficient_of_variation_weights(data, correlation_settings)
        
        # æ ‡å‡†åŒ–å¤„ç†
        data_normalized = (data_processed - data_processed.min()) / (data_processed.max() - data_processed.min())
        data_normalized = data_normalized.fillna(0)
        
        # é¿å…0å€¼ï¼Œä½¿ç”¨æ›´å°çš„æ›¿ä»£å€¼
        epsilon = 1e-12
        data_normalized = data_normalized.replace(0, epsilon)
        
        # è®¡ç®—ç†µå€¼
        entropy = np.zeros(n)
        for j in range(n):
            col_sum = data_normalized.iloc[:, j].sum()
            if col_sum > 0:
                p = data_normalized.iloc[:, j] / col_sum
                p = p.replace(0, epsilon)
                # å¢å¼ºç†µå€¼è®¡ç®—çš„ç¨³å®šæ€§
                log_p = np.log(p)
                entropy[j] = -1 / np.log(m) * np.sum(p * log_p)
            else:
                entropy[j] = 1.0
        
        # è®¡ç®—æƒé‡
        entropy_diff = 1 - entropy
        weights_sum = np.sum(entropy_diff)
        
        if weights_sum == 0:
            # å¦‚æœæ‰€æœ‰æƒé‡éƒ½ç›¸åŒï¼Œä½¿ç”¨å˜å¼‚ç³»æ•°æ³•ä½œä¸ºå¤‡é€‰
            st.warning("ç†µæƒæ³•è®¡ç®—å‡ºç°å¼‚å¸¸ï¼Œè‡ªåŠ¨åˆ‡æ¢åˆ°å˜å¼‚ç³»æ•°æ³•")
            return self.calculate_coefficient_of_variation_weights(data, correlation_settings)
        
        weights = entropy_diff / weights_sum
        
        return weights, correlation_settings

    def calculate_carbon_emission_basic(self, data_row):
        total_emission = 0
        emission_details = {}
        
        if 'electricity_kwh' in data_row and pd.notna(data_row['electricity_kwh']):
            electricity_emission = data_row['electricity_kwh'] * self.emission_factors['electricity']
            total_emission += electricity_emission
            emission_details['ç”µåŠ›'] = electricity_emission
            
        if 'natural_gas_m3' in data_row and pd.notna(data_row['natural_gas_m3']):
            gas_emission = data_row['natural_gas_m3'] * self.emission_factors['natural_gas']
            total_emission += gas_emission
            emission_details['å¤©ç„¶æ°”'] = gas_emission
            
        if 'diesel_l' in data_row and pd.notna(data_row['diesel_l']):
            diesel_emission = data_row['diesel_l'] * self.emission_factors['diesel']
            total_emission += diesel_emission
            emission_details['æŸ´æ²¹'] = diesel_emission
            
        if 'operation_hours' in data_row and pd.notna(data_row['operation_hours']):
            time_emission = data_row['operation_hours'] * self.time_factors['equipment_operation']
            total_emission += time_emission
            emission_details['è®¾å¤‡è¿è¡Œæ—¶é—´'] = time_emission
            
        if 'transport_hours' in data_row and pd.notna(data_row['transport_hours']):
            transport_emission = data_row['transport_hours'] * self.time_factors['transportation']
            total_emission += transport_emission
            emission_details['è¿è¾“æ—¶é—´'] = transport_emission
            
        return total_emission, emission_details

    def calculate_carbon_emission_custom(self, data_row, custom_columns, weights):
        total_emission, emission_details = self.calculate_carbon_emission_basic(data_row)
        
        if len(custom_columns) > 0 and weights is not None:
            custom_emission = 0
            for i, col in enumerate(custom_columns):
                if col in data_row and pd.notna(data_row[col]):
                    factor_config = self.custom_factors.get(col, {})
                    emission_factor = factor_config.get('emission_factor', 1.0)
                    factor_emission = data_row[col] * emission_factor * weights[i]
                    custom_emission += factor_emission
                    emission_details[f'è‡ªå®šä¹‰-{col}'] = factor_emission
            total_emission += custom_emission
            
        return total_emission, emission_details

    def assess_multiple_processes(self, df, custom_columns=None, correlation_settings=None):
        if custom_columns is None:
            custom_columns = []
            
        # é€‰æ‹©ç”¨äºæƒé‡è®¡ç®—çš„åˆ—
        if len(custom_columns) == 0:
            indicator_columns = ['electricity_cost', 'fuel_cost', 'operation_hours', 'production_volume']
            available_columns = [col for col in indicator_columns if col in df.columns]
        else:
            available_columns = [col for col in custom_columns if col in df.columns]
        
        if len(available_columns) < 2:
            st.error("è‡³å°‘éœ€è¦2ä¸ªè¯„ä¼°æŒ‡æ ‡æ‰èƒ½è¿›è¡Œç†µæƒæ³•åˆ†æ")
            return None, None, None, None
        
        # ä½¿ç”¨å¢å¼ºç‰ˆç†µæƒæ³•è®¡ç®—æƒé‡
        weights, processed_correlations = self.calculate_enhanced_entropy_weights(
            df[available_columns], correlation_settings)
        
        # æ˜¾ç¤ºæƒé‡è®¡ç®—æ–¹æ³•
        sample_count = len(df)
        if sample_count <= 3:
            st.info(f"æ ·æœ¬æ•°é‡: {sample_count}ï¼Œå·²ä½¿ç”¨å˜å¼‚ç³»æ•°æ³•ç¡®ä¿æƒé‡å·®å¼‚åŒ–")
        else:
            st.info(f"æ ·æœ¬æ•°é‡: {sample_count}ï¼Œä½¿ç”¨ç†µæƒæ³•è®¡ç®—æƒé‡")
        
        # è®¡ç®—ç¢³æ’æ”¾
        emissions = []
        emission_details_list = []
        for idx, row in df.iterrows():
            if len(custom_columns) > 0:
                emission, details = self.calculate_carbon_emission_custom(row, available_columns, weights)
            else:
                emission, details = self.calculate_carbon_emission_basic(row)
            emissions.append(emission)
            emission_details_list.append(details)
        
        df['carbon_emission'] = emissions
        
        # è®¡ç®—åŠ æƒå¾—åˆ†
        weighted_scores = np.zeros(len(df))
        for i, col in enumerate(available_columns):
            weight_sign = 1
            if correlation_settings and col in correlation_settings:
                if correlation_settings[col] == 'negative':
                    weight_sign = -1
            weighted_scores += df[col] * weights[i] * weight_sign
        
        df['weighted_score'] = weighted_scores
        
        return df, weights, emission_details_list, available_columns

def create_custom_factors_interface():
    st.sidebar.header("ğŸ›ï¸ è‡ªå®šä¹‰è¯„ä¼°è¦ç´ ")
    num_factors = st.sidebar.number_input("è¯„ä¼°è¦ç´ æ•°é‡", min_value=2, max_value=10, value=4)
    
    custom_factors = {}
    correlation_settings = {}
    custom_columns = []
    
    for i in range(num_factors):
        st.sidebar.subheader(f"è¦ç´  {i+1}")
        factor_name = st.sidebar.text_input(
            f"è¦ç´ åç§° {i+1}", 
            value=f"factor_{i+1}", 
            key=f"factor_name_{i}"
        )
        emission_factor = st.sidebar.number_input(
            f"æ’æ”¾å› å­ {i+1} (kg CO2/å•ä½)", 
            value=1.0, 
            step=0.1, 
            key=f"emission_factor_{i}"
        )
        correlation = st.sidebar.selectbox(
            f"ä¸ç¢³æ’æ”¾ç›¸å…³æ€§ {i+1}", 
            ["positive", "negative"], 
            format_func=lambda x: "æ­£ç›¸å…³ (æ•°å€¼è¶Šå¤§ï¼Œæ’æ”¾è¶Šå¤§)" if x == "positive" else "è´Ÿç›¸å…³ (æ•°å€¼è¶Šå¤§ï¼Œæ’æ”¾è¶Šå°)", 
            key=f"correlation_{i}"
        )
        
        custom_factors[factor_name] = {
            'emission_factor': emission_factor,
            'correlation': correlation
        }
        correlation_settings[factor_name] = correlation
        custom_columns.append(factor_name)
    
    return custom_factors, correlation_settings, custom_columns

def manual_input_table_interface(assessment, assessment_mode, custom_columns=None, correlation_settings=None):
    st.subheader("ğŸ“ æ‰‹åŠ¨è¾“å…¥å¤šä¸ªæµç¨‹æ•°æ®ï¼ˆå¯ç›´æ¥ç¼–è¾‘ï¼‰")
    
    if assessment_mode == "é¢„è®¾æ¨¡å¼ (ç”µè´¹ã€ç‡ƒæ–™è´¹ç­‰)":
        default_data = [
            {"æµç¨‹åç§°": "æµç¨‹A", "ç”µåŠ›æ¶ˆè€— (kWh)": 120, "ç”µè´¹ (å…ƒ)": 78, "å¤©ç„¶æ°”æ¶ˆè€— (mÂ³)": 25,
             "ç‡ƒæ–™è´¹ (å…ƒ)": 75, "è¿è¡Œæ—¶é—´ (å°æ—¶)": 10, "è¿è¾“æ—¶é—´ (å°æ—¶)": 3, "äº§é‡ (å•ä½)": 1200, "æŸ´æ²¹æ¶ˆè€— (L)": 15},
            {"æµç¨‹åç§°": "æµç¨‹B", "ç”µåŠ›æ¶ˆè€— (kWh)": 85, "ç”µè´¹ (å…ƒ)": 55, "å¤©ç„¶æ°”æ¶ˆè€— (mÂ³)": 15,
             "ç‡ƒæ–™è´¹ (å…ƒ)": 45, "è¿è¡Œæ—¶é—´ (å°æ—¶)": 6, "è¿è¾“æ—¶é—´ (å°æ—¶)": 2, "äº§é‡ (å•ä½)": 800, "æŸ´æ²¹æ¶ˆè€— (L)": 8},
            {"æµç¨‹åç§°": "æµç¨‹C", "ç”µåŠ›æ¶ˆè€— (kWh)": 200, "ç”µè´¹ (å…ƒ)": 130, "å¤©ç„¶æ°”æ¶ˆè€— (mÂ³)": 40,
             "ç‡ƒæ–™è´¹ (å…ƒ)": 120, "è¿è¡Œæ—¶é—´ (å°æ—¶)": 16, "è¿è¾“æ—¶é—´ (å°æ—¶)": 5, "äº§é‡ (å•ä½)": 2000, "æŸ´æ²¹æ¶ˆè€— (L)": 25},
        ]
        df_manual = pd.DataFrame(default_data)
    else:
        if not custom_columns:
            st.error("è¯·å…ˆé…ç½®è‡ªå®šä¹‰è¦ç´ ")
            return None
        
        default_data = []
        for i in range(3):
            row = {"æµç¨‹åç§°": f"æµç¨‹{chr(65+i)}"}
            for col in custom_columns:
                corr_text = " (æ­£ç›¸å…³)" if correlation_settings[col] == 'positive' else " (è´Ÿç›¸å…³)"
                # ä¸ºå°æ ·æœ¬ç”Ÿæˆæ›´æœ‰å·®å¼‚çš„æ•°æ®
                base_value = 100.0
                if correlation_settings[col] == 'positive':
                    row[col + corr_text] = base_value + i * 50.0  # åˆ›é€ æ›´å¤§å·®å¼‚
                else:
                    row[col + corr_text] = base_value - i * 30.0  # è´Ÿç›¸å…³æ•°æ®
            default_data.append(row)
        df_manual = pd.DataFrame(default_data)
    
    edited_df = st.data_editor(df_manual, num_rows="dynamic", use_container_width=True)
    
    # åˆ—åæ˜ å°„
    if assessment_mode == "é¢„è®¾æ¨¡å¼ (ç”µè´¹ã€ç‡ƒæ–™è´¹ç­‰)":
        edited_df.columns = [
            'process_name', 'electricity_kwh', 'electricity_cost', 'natural_gas_m3',
            'fuel_cost', 'operation_hours', 'transport_hours', 'production_volume', 'diesel_l'
        ]
    else:
        edited_df.columns = ['process_name'] + custom_columns
    
    return edited_df

def display_results(df, weights, details_list, used_columns, assessment, custom_factors=None, correlation_settings=None):
    st.header("ğŸ“Š åˆ†æç»“æœ")
    
    # è·å–ä¸­æ–‡å­—ä½“å±æ€§
    font_prop = get_chinese_font_prop()
    
    # æ„å»ºç»“æœè¡¨æ ¼
    if 'production_volume' in df.columns:
        df['emission_intensity'] = df['carbon_emission'] / df['production_volume']
        result_columns = ['process_name', 'carbon_emission', 'emission_intensity', 'weighted_score']
        column_names = ['æµç¨‹åç§°', 'æ€»ç¢³æ’æ”¾(kg CO2)', 'æ’æ”¾å¼ºåº¦(kg CO2/å•ä½)', 'åŠ æƒè¯„åˆ†']
    else:
        result_columns = ['process_name', 'carbon_emission', 'weighted_score']
        column_names = ['æµç¨‹åç§°', 'æ€»ç¢³æ’æ”¾(kg CO2)', 'åŠ æƒè¯„åˆ†']
    
    result_df = df[result_columns].copy()
    result_df.columns = column_names
    result_df = result_df.sort_values('æ€»ç¢³æ’æ”¾(kg CO2)')
    st.dataframe(result_df.round(3))
    
    # æƒé‡ä¿¡æ¯è¡¨æ ¼
    st.subheader("âš–ï¸ ç†µæƒæ³•è®¡ç®—æƒé‡")
    weights_data = []
    for i, col in enumerate(used_columns):
        correlation_type = "æ­£ç›¸å…³"
        if correlation_settings and col in correlation_settings:
            correlation_type = "æ­£ç›¸å…³" if correlation_settings[col] == "positive" else "è´Ÿç›¸å…³"
        
        emission_factor = "ç³»ç»Ÿé»˜è®¤"
        if custom_factors and col in custom_factors:
            emission_factor = f"{custom_factors[col]['emission_factor']:.3f}"
        
        weights_data.append({
            'è¯„ä¼°æŒ‡æ ‡': col,
            'æƒé‡': weights[i],
            'æƒé‡ç™¾åˆ†æ¯”': f"{weights[i] * 100:.2f}%",
            'ç›¸å…³æ€§': correlation_type,
            'æ’æ”¾å› å­': emission_factor
        })
    
    weights_df = pd.DataFrame(weights_data)
    st.dataframe(weights_df)
    
    # æ£€æŸ¥æƒé‡å·®å¼‚å¹¶ç»™å‡ºè¯´æ˜
    weight_std = np.std(weights)
    weight_range = np.max(weights) - np.min(weights)
    
    if weight_std < 0.05:
        st.warning(f"âš ï¸ æƒé‡å·®å¼‚è¾ƒå° (æ ‡å‡†å·®: {weight_std:.4f})ï¼Œè¿™å¯èƒ½æ˜¯ç”±äºæ ·æœ¬æ•°é‡å°‘æˆ–æŒ‡æ ‡é—´ç›¸å…³æ€§è¾ƒé«˜å¯¼è‡´çš„")
    else:
        st.success(f"âœ… æƒé‡åˆ†å¸ƒåˆç† (æ ‡å‡†å·®: {weight_std:.4f}ï¼Œæƒé‡èŒƒå›´: {weight_range:.4f})")
    
    # å¯è§†åŒ–åˆ†æ
    st.subheader("ğŸ“ˆ å¯è§†åŒ–åˆ†æ")
    col1, col2 = st.columns(2)
    
    with col1:
        fig, ax = plt.subplots(figsize=(10, 6))
        bars = ax.bar(df['process_name'], df['carbon_emission'], 
                     color=plt.cm.RdYlGn_r(np.linspace(0.2, 0.8, len(df))))
        ax.set_title('å„æµç¨‹ç¢³æ’æ”¾å¯¹æ¯”', fontproperties=font_prop)
        ax.set_ylabel('ç¢³æ’æ”¾é‡ (kg CO2)', fontproperties=font_prop)
        ax.tick_params(axis='x', rotation=45)
        
        # è®¾ç½®xè½´æ ‡ç­¾å­—ä½“
        for tick in ax.get_xticklabels():
            tick.set_fontproperties(font_prop)
        for tick in ax.get_yticklabels():
            tick.set_fontproperties(font_prop)
            
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar in bars:
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width() / 2., height, 
                   f'{height:.1f}', ha='center', va='bottom', fontproperties=font_prop)
        
        plt.tight_layout()
        st.pyplot(fig)
    
    with col2:
        fig, ax = plt.subplots(figsize=(8, 8))
        colors = plt.cm.Set3(np.linspace(0, 1, len(weights)))
        
        # åˆ›å»ºå¸¦ç›¸å…³æ€§æ ‡æ³¨çš„æ ‡ç­¾
        labels_with_correlation = []
        for col in used_columns:
            correlation_type = "+"
            if correlation_settings and col in correlation_settings:
                correlation_type = "+" if correlation_settings[col] == "positive" else "-"
            labels_with_correlation.append(f"{col}({correlation_type})")
        
        wedges, texts, autotexts = ax.pie(weights, labels=labels_with_correlation, 
                                        autopct='%1.1f%%', startangle=90, colors=colors)
        ax.set_title('ç†µæƒæ³• - å„æŒ‡æ ‡æƒé‡åˆ†å¸ƒ\n(+æ­£ç›¸å…³, -è´Ÿç›¸å…³)', fontproperties=font_prop)
        
        # è®¾ç½®é¥¼å›¾æ ‡ç­¾å­—ä½“
        for text in texts:
            text.set_fontproperties(font_prop)
        for autotext in autotexts:
            autotext.set_fontproperties(font_prop)
        
        st.pyplot(fig)
    
    # å…¶ä»–åˆ†æå›¾è¡¨
    if 'emission_intensity' in df.columns:
        st.subheader("ğŸ“Š æ’æ”¾å¼ºåº¦åˆ†æ")
        fig, ax = plt.subplots(figsize=(12, 6))
        bars = ax.bar(df['process_name'], df['emission_intensity'], 
                     color=plt.cm.Blues(np.linspace(0.3, 0.8, len(df))))
        ax.set_title('å„æµç¨‹ç¢³æ’æ”¾å¼ºåº¦å¯¹æ¯”', fontproperties=font_prop)
        ax.set_ylabel('æ’æ”¾å¼ºåº¦ (kg CO2/å•ä½äº§å“)', fontproperties=font_prop)
        ax.tick_params(axis='x', rotation=45)
        
        for tick in ax.get_xticklabels():
            tick.set_fontproperties(font_prop)
        for tick in ax.get_yticklabels():
            tick.set_fontproperties(font_prop)
            
        for bar in bars:
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width() / 2., height, 
                   f'{height:.3f}', ha='center', va='bottom', fontproperties=font_prop)
        
        plt.tight_layout()
        st.pyplot(fig)
    
    # ç»¼åˆè¯„åˆ†åˆ†æ
    st.subheader("ğŸ¯ ç»¼åˆè¯„åˆ†åˆ†æ")
    fig, ax = plt.subplots(figsize=(12, 6))
    sorted_df = df.sort_values('weighted_score', ascending=True)
    bars = ax.barh(sorted_df['process_name'], sorted_df['weighted_score'], 
                   color=plt.cm.RdYlGn(np.linspace(0.2, 0.8, len(sorted_df))))
    ax.set_title('å„æµç¨‹ç»¼åˆè¯„åˆ†å¯¹æ¯” (è€ƒè™‘æƒé‡å’Œç›¸å…³æ€§)', fontproperties=font_prop)
    ax.set_xlabel('åŠ æƒç»¼åˆè¯„åˆ†', fontproperties=font_prop)
    
    for tick in ax.get_xticklabels():
        tick.set_fontproperties(font_prop)
    for tick in ax.get_yticklabels():
        tick.set_fontproperties(font_prop)
    
    for i, bar in enumerate(bars):
        width = bar.get_width()
        ax.text(width, bar.get_y() + bar.get_height() / 2., 
               f'{width:.3f}', ha='left' if width >= 0 else 'right', 
               va='center', fontproperties=font_prop)
    
    plt.tight_layout()
    st.pyplot(fig)
    
    # è¦ç´ ç›¸å…³æ€§åˆ†æï¼ˆä»…è‡ªå®šä¹‰æ¨¡å¼ï¼‰
    if custom_factors and correlation_settings:
        st.subheader("ğŸ” è¦ç´ ç›¸å…³æ€§åˆ†æ")
        factor_columns = [col for col in used_columns if col in df.columns]
        if len(factor_columns) > 1:
            corr_matrix = df[factor_columns].corr()
            fig, ax = plt.subplots(figsize=(10, 8))
            sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, 
                       square=True, fmt='.3f', ax=ax)
            ax.set_title('è¯„ä¼°è¦ç´ ç›¸å…³æ€§çŸ©é˜µ', fontproperties=font_prop)
            
            for tick in ax.get_xticklabels():
                tick.set_fontproperties(font_prop)
            for tick in ax.get_yticklabels():
                tick.set_fontproperties(font_prop)
            
            st.pyplot(fig)
        
        # è¦ç´ å½±å“åŠ›åˆ†æ
        st.subheader("ğŸ’ª è¦ç´ å½±å“åŠ›åˆ†æ")
        influence_data = []
        for i, col in enumerate(used_columns):
            if col in df.columns:
                correlation_type = correlation_settings.get(col, 'positive')
                weight = weights[i]
                std_dev = df[col].std()
                influence_score = weight * std_dev
                influence_data.append({
                    'è¦ç´ åç§°': col,
                    'æƒé‡': weight,
                    'æ ‡å‡†å·®': std_dev,
                    'å½±å“åŠ›å¾—åˆ†': influence_score,
                    'ç›¸å…³æ€§': 'æ­£ç›¸å…³' if correlation_type == 'positive' else 'è´Ÿç›¸å…³'
                })
        
        influence_df = pd.DataFrame(influence_data)
        influence_df = influence_df.sort_values('å½±å“åŠ›å¾—åˆ†', ascending=False)
        st.dataframe(influence_df.round(4))
        
        # å½±å“åŠ›å¯è§†åŒ–
        fig, ax = plt.subplots(figsize=(12, 6))
        colors = ['green' if corr == 'æ­£ç›¸å…³' else 'red' for corr in influence_df['ç›¸å…³æ€§']]
        bars = ax.bar(influence_df['è¦ç´ åç§°'], influence_df['å½±å“åŠ›å¾—åˆ†'], 
                     color=colors, alpha=0.7)
        ax.set_title('å„è¦ç´ å½±å“åŠ›å¾—åˆ† (ç»¿è‰²:æ­£ç›¸å…³, çº¢è‰²:è´Ÿç›¸å…³)', fontproperties=font_prop)
        ax.set_ylabel('å½±å“åŠ›å¾—åˆ† (æƒé‡ Ã— æ ‡å‡†å·®)', fontproperties=font_prop)
        ax.tick_params(axis='x', rotation=45)
        
        for tick in ax.get_xticklabels():
            tick.set_fontproperties(font_prop)
        for tick in ax.get_yticklabels():
            tick.set_fontproperties(font_prop)
            
        for bar in bars:
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width() / 2., height, 
                   f'{height:.3f}', ha='center', va='bottom', fontproperties=font_prop)
        
        plt.tight_layout()
        st.pyplot(fig)
    
    # æ”¹è¿›å»ºè®®
    st.subheader("ğŸ’¡ æ”¹è¿›å»ºè®®")
    max_emission_idx = df['carbon_emission'].idxmax()
    min_emission_idx = df['carbon_emission'].idxmin()
    max_process = df.loc[max_emission_idx, 'process_name']
    min_process = df.loc[min_emission_idx, 'process_name']
    max_emission = df.loc[max_emission_idx, 'carbon_emission']
    min_emission = df.loc[min_emission_idx, 'carbon_emission']
    improvement_potential = max_emission - min_emission
    
    st.info(f"""
    **ğŸŒŸ æœ€ä¼˜æµç¨‹**: {min_process} (ç¢³æ’æ”¾: {min_emission:.1f} kg CO2)
    
    **âš ï¸ éœ€æ”¹è¿›æµç¨‹**: {max_process} (ç¢³æ’æ”¾: {max_emission:.1f} kg CO2)
    
    **ğŸ¯ æ”¹è¿›æ½œåŠ›**: å¦‚æœå°†æœ€é«˜æ’æ”¾æµç¨‹ä¼˜åŒ–åˆ°æœ€ä½³æ°´å¹³ï¼Œå¯å‡å°‘ {improvement_potential:.1f} kg CO2 æ’æ”¾
    """)
    
    # å…·ä½“æ”¹è¿›å»ºè®®
    if len(used_columns) > 0:
        st.subheader("ğŸ”§ å…·ä½“æ”¹è¿›å»ºè®®")
        weight_importance = list(zip(used_columns, weights))
        weight_importance.sort(key=lambda x: x[1], reverse=True)
        top_factors = weight_importance[:3]
        suggestions = []
        for factor, weight in top_factors:
            correlation_type = "æ­£ç›¸å…³"
            if correlation_settings and factor in correlation_settings:
                correlation_type = "æ­£ç›¸å…³" if correlation_settings[factor] == "positive" else "è´Ÿç›¸å…³"
            if correlation_type == "æ­£ç›¸å…³":
                suggestion = f"é™ä½ **{factor}** çš„æ•°å€¼"
            else:
                suggestion = f"æé«˜ **{factor}** çš„æ•°å€¼"
            suggestions.append(f"- {suggestion} (æƒé‡: {weight:.3f})")
        st.markdown("**ä¼˜å…ˆæ”¹è¿›å»ºè®®** (æŒ‰æƒé‡æ’åº):")
        for suggestion in suggestions:
            st.markdown(suggestion)
    
    if len(df) > 1 and len(used_columns) > 1:
        st.subheader("ğŸ“ˆ æ•æ„Ÿæ€§åˆ†æï¼ˆå¼¹æ€§ç³»æ•°ï¼‰")
    sensitivity_data = []
    
    # è®¡ç®—å‡å€¼
    emission_mean = df['carbon_emission'].mean()
    
    for col in used_columns:
        if col in df.columns and col != 'carbon_emission':
            col_mean = df[col].mean()
            col_std = df[col].std()
            
            if col_mean > 0 and col_std > 0:
                # å¼¹æ€§ç³»æ•° = (æ’æ”¾é‡å˜åŒ–ç™¾åˆ†æ¯”) / (å› ç´ å˜åŒ–ç™¾åˆ†æ¯”)
                # ç”¨å˜å¼‚ç³»æ•°è¿‘ä¼¼
                emission_cv = df['carbon_emission'].std() / emission_mean
                factor_cv = col_std / col_mean
                
                if factor_cv > 0:
                    elasticity = emission_cv / factor_cv
                    
                    sensitivity_data.append({
                        'è¦ç´ ': col,
                        'å¼¹æ€§ç³»æ•°': elasticity,
                        'å› ç´ å˜å¼‚ç³»æ•°': factor_cv,
                        'æ’æ”¾é‡å˜å¼‚ç³»æ•°': emission_cv
                    })
    
    if sensitivity_data:
        sensitivity_df = pd.DataFrame(sensitivity_data)
        sensitivity_df = sensitivity_df.sort_values('å¼¹æ€§ç³»æ•°', ascending=False)
        st.write("**å¼¹æ€§ç³»æ•°æ’åº** (è¡¨ç¤ºå› ç´ å˜åŒ–1%æ—¶æ’æ”¾é‡å˜åŒ–ç™¾åˆ†ä¹‹å‡ ):")
        st.dataframe(sensitivity_df.round(4))
    
    # åœ¨ display_results å‡½æ•°ä¸­ï¼Œæ‰¾åˆ° "ç»“æœå¯¼å‡º" éƒ¨åˆ†ï¼Œæ›¿æ¢ä¸ºä»¥ä¸‹ä»£ç ï¼š

    st.subheader("ğŸ“¥ ç»“æœå¯¼å‡º")
    col1, col2 = st.columns(2)
    
    with col1:
        # å‡†å¤‡è¯¦ç»†åˆ†æç»“æœæ•°æ®
        export_df = df.copy()
        export_df['è¯„ä¼°æ¨¡å¼'] = "è‡ªå®šä¹‰æ¨¡å¼" if custom_factors else "é¢„è®¾æ¨¡å¼"
        for i, col in enumerate(used_columns):
            if col in export_df.columns:
                export_df[f'{col}_æƒé‡'] = weights[i]
        result_csv = export_df.to_csv(index=False).encode('utf-8-sig')
        
        # ä½¿ç”¨ st.download_button æ›¿ä»£ st.button
        st.download_button(
            label="ğŸ“Š ä¸‹è½½è¯¦ç»†åˆ†æç»“æœ",
            data=result_csv,
            file_name=f"ç¢³æ’æ”¾è¯„ä¼°è¯¦ç»†ç»“æœ_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
            mime="text/csv",
            key="download_results"  # æ·»åŠ å”¯ä¸€key
        )
    
    with col2:
        # å‡†å¤‡æƒé‡é…ç½®æ•°æ®
        config_data = []
        for i, col in enumerate(used_columns):
            config_data.append({
                'è¦ç´ åç§°': col,
                'æƒé‡': weights[i],
                'ç›¸å…³æ€§': correlation_settings.get(col, 'æ­£ç›¸å…³') if correlation_settings else 'æ­£ç›¸å…³',
                'æ’æ”¾å› å­': custom_factors.get(col, {}).get('emission_factor', 'ç³»ç»Ÿé»˜è®¤') if custom_factors else 'ç³»ç»Ÿé»˜è®¤'
            })
        config_df = pd.DataFrame(config_data)
        config_csv = config_df.to_csv(index=False).encode('utf-8-sig')
        
        # ä½¿ç”¨ st.download_button æ›¿ä»£ st.button
        st.download_button(
            label="ğŸ“‹ ä¸‹è½½æƒé‡é…ç½®",
            data=config_csv,
            file_name=f"è¯„ä¼°æƒé‡é…ç½®_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
            mime="text/csv",
            key="download_config"  # æ·»åŠ å”¯ä¸€key
        )

def main():
    st.set_page_config(page_title="ä¼ä¸šç¢³æ’æ”¾è¯„ä¼°ç³»ç»Ÿ", layout="wide")

    # è®¾ç½®ä¸­æ–‡å­—ä½“
    setup_chinese_font()
    
    st.title("ğŸŒ± åŸºäºç†µæƒæ³•çš„ä¼ä¸šç¢³æ’æ”¾è¯„ä¼°ç³»ç»Ÿ")
    st.markdown("é€šè¿‡è‡ªå®šä¹‰è¯„ä¼°è¦ç´ ï¼Œå¿«é€Ÿè¯„ä¼°ç”Ÿäº§æµç¨‹ç¢³æ’æ”¾")
    
    # å­—ä½“çŠ¶æ€æ˜¾ç¤º
    font_path = 'simhei.ttf'
    if os.path.exists(font_path):
        st.success("âœ… ä¸­æ–‡å­—ä½“å·²åŠ è½½ï¼Œå›¾è¡¨å°†æ­£ç¡®æ˜¾ç¤ºä¸­æ–‡")
    else:
        st.warning("âš ï¸ æœªæ‰¾åˆ°simhei.ttfå­—ä½“æ–‡ä»¶ï¼Œè¯·ç¡®ä¿å­—ä½“æ–‡ä»¶åœ¨é¡¹ç›®æ ¹ç›®å½•")
    
    assessment = CarbonEmissionAssessment()
    st.header("ğŸ¯ è¯„ä¼°æ¨¡å¼é€‰æ‹©")
    assessment_mode = st.radio(
        "é€‰æ‹©è¯„ä¼°æ¨¡å¼:",
        ["é¢„è®¾æ¨¡å¼ (ç”µè´¹ã€ç‡ƒæ–™è´¹ç­‰)", "è‡ªå®šä¹‰æ¨¡å¼ (ç”¨æˆ·å®šä¹‰è¦ç´ )"],
        help="é¢„è®¾æ¨¡å¼ä½¿ç”¨ç³»ç»Ÿå†…ç½®çš„è¯„ä¼°è¦ç´ ï¼›è‡ªå®šä¹‰æ¨¡å¼å…è®¸æ‚¨å®Œå…¨è‡ªå®šä¹‰è¯„ä¼°è¦ç´ å’Œç›¸å…³æ€§"
    )
    custom_factors = {}
    correlation_settings = {}
    custom_columns = []
    if assessment_mode == "è‡ªå®šä¹‰æ¨¡å¼ (ç”¨æˆ·å®šä¹‰è¦ç´ )":
        custom_factors, correlation_settings, custom_columns = create_custom_factors_interface()
        assessment.set_custom_factors(custom_factors)
        with st.expander("ğŸ“‹ å½“å‰è¦ç´ é…ç½®"):
            config_df = pd.DataFrame([
                {
                    'è¦ç´ åç§°': name,
                    'æ’æ”¾å› å­': config['emission_factor'],
                    'ç›¸å…³æ€§': 'æ­£ç›¸å…³' if config['correlation'] == 'positive' else 'è´Ÿç›¸å…³'
                }
                for name, config in custom_factors.items()
            ])
            st.dataframe(config_df)
    if assessment_mode == "é¢„è®¾æ¨¡å¼ (ç”µè´¹ã€ç‡ƒæ–™è´¹ç­‰)":
        st.sidebar.header("âš™ï¸ ç³»ç»Ÿå‚æ•°è®¾ç½®")
        st.sidebar.subheader("æ’æ”¾å› å­è°ƒæ•´")
        electricity_factor = st.sidebar.number_input("ç”µåŠ›æ’æ”¾å› å­ (kg CO2/kWh)", value=0.6205, step=0.01)
        gas_factor = st.sidebar.number_input("å¤©ç„¶æ°”æ’æ”¾å› å­ (kg CO2/mÂ³)", value=2.162, step=0.01)
        assessment.emission_factors['electricity'] = electricity_factor
        assessment.emission_factors['natural_gas'] = gas_factor
    
    st.header("ğŸ“Š æ•°æ®è¾“å…¥")
    input_method = st.radio("é€‰æ‹©æ•°æ®è¾“å…¥æ–¹å¼:", ["ä½¿ç”¨ç¤ºä¾‹æ•°æ®", "æ‰¹é‡ä¸Šä¼ CSVæ–‡ä»¶", "æ‰‹åŠ¨è¾“å…¥å¤šä¸ªæµç¨‹"])
    df = None
    
    if input_method == "ä½¿ç”¨ç¤ºä¾‹æ•°æ®":
        if assessment_mode == "è‡ªå®šä¹‰æ¨¡å¼ (ç”¨æˆ·å®šä¹‰è¦ç´ )":
            def create_sample_data_with_custom_factors(custom_columns, correlation_settings):
                np.random.seed(42)
                sample_data = {'process_name': [f'æµç¨‹{chr(65+i)}' for i in range(5)]}
                for i, col in enumerate(custom_columns):
                    if correlation_settings[col] == 'positive':
                        base_values = [50 + i*20 + np.random.normal(0, 10) for i in range(5)]
                    else:
                        base_values = [150 - i*20 + np.random.normal(0, 10) for i in range(5)]
                    sample_data[col] = [max(10, val) for val in base_values]
                return pd.DataFrame(sample_data)
            
            df = create_sample_data_with_custom_factors(custom_columns, correlation_settings)
            st.subheader("ğŸ“‹ è‡ªå®šä¹‰ç¤ºä¾‹æ•°æ®")
            st.dataframe(df.round(2))
            st.info("""
            **ç¤ºä¾‹æ•°æ®è¯´æ˜**ï¼š
            - æ­£ç›¸å…³è¦ç´ ï¼šæ•°å€¼è¶Šå¤§ï¼Œé¢„æœŸç¢³æ’æ”¾è¶Šå¤§
            - è´Ÿç›¸å…³è¦ç´ ï¼šæ•°å€¼è¶Šå¤§ï¼Œé¢„æœŸç¢³æ’æ”¾è¶Šå°
            - æ•°æ®å·²æ ¹æ®ç›¸å…³æ€§è®¾ç½®ç”Ÿæˆç›¸åº”è¶‹åŠ¿
            """)
        else:
            sample_data = {
                'process_name': ['æµç¨‹A', 'æµç¨‹B', 'æµç¨‹C', 'æµç¨‹D', 'æµç¨‹E'],
                'electricity_kwh': [120, 85, 200, 95, 150],
                'electricity_cost': [78, 55, 130, 62, 98],
                'natural_gas_m3': [25, 15, 40, 18, 30],
                'fuel_cost': [75, 45, 120, 54, 90],
                'operation_hours': [10, 6, 16, 8, 12],
                'transport_hours': [3, 2, 5, 2.5, 4],
                'production_volume': [1200, 800, 2000, 900, 1500],
                'diesel_l': [15, 8, 25, 10, 18]
            }
            df = pd.DataFrame(sample_data)
            st.subheader("ğŸ“‹ é¢„è®¾ç¤ºä¾‹æ•°æ®")
            st.dataframe(df)
    
    elif input_method == "æ‰¹é‡ä¸Šä¼ CSVæ–‡ä»¶":
        uploaded_file = st.file_uploader("é€‰æ‹©CSVæ–‡ä»¶", type=['csv'])
        if uploaded_file is not None:
            try:
                df = pd.read_csv(uploaded_file)
                st.subheader("ğŸ“‹ ä¸Šä¼ çš„æ•°æ®")
                st.dataframe(df)
            except Exception as e:
                st.error(f"æ–‡ä»¶è¯»å–é”™è¯¯: {e}")
    
    else:
        df = manual_input_table_interface(assessment, assessment_mode, custom_columns, correlation_settings)
    
    if df is not None and not df.empty:
        # ä½¿ç”¨ session_state å­˜å‚¨ä¸­é—´å˜é‡ï¼Œé¿å… rerun åä¸¢å¤±
        if 'analyzed' not in st.session_state:
            st.session_state['analyzed'] = False

        # å¼€å§‹åˆ†ææŒ‰é’® â€”â€” ç‚¹å‡»åæŠŠç»“æœå†™å…¥ session_state
        if st.button("ğŸš€ å¼€å§‹åˆ†æ", key="start_analysis"):
            if assessment_mode == "è‡ªå®šä¹‰æ¨¡å¼ (ç”¨æˆ·å®šä¹‰è¦ç´ )":
                analyzed_df, weights, details_list, used_columns = assessment.assess_multiple_processes(
                    df, custom_columns, correlation_settings)
            else:
                analyzed_df, weights, details_list, used_columns = assessment.assess_multiple_processes(df)

            if analyzed_df is not None:
                # å°†ç»“æœæŒä¹…åŒ–åˆ° session_stateï¼ˆå¯åºåˆ—åŒ–çš„å¯¹è±¡ï¼‰
                st.session_state['analyzed'] = True
                st.session_state['analyzed_df'] = analyzed_df
                st.session_state['analyzed_weights'] = weights
                st.session_state['analyzed_details'] = details_list
                st.session_state['analyzed_used_columns'] = used_columns
                # ä¿å­˜å½“å‰æ¨¡å¼ä¸é…ç½®ï¼Œä¾¿äº display å’Œä¸‹è½½ä½¿ç”¨
                st.session_state['assessment_mode'] = assessment_mode
                st.session_state['custom_factors'] = custom_factors if assessment_mode == "è‡ªå®šä¹‰æ¨¡å¼ (ç”¨æˆ·å®šä¹‰è¦ç´ )" else None
                st.session_state['correlation_settings'] = correlation_settings if assessment_mode == "è‡ªå®šä¹‰æ¨¡å¼ (ç”¨æˆ·å®šä¹‰è¦ç´ )" else None

        # å¦‚æœ session_state è¡¨ç¤ºæ­¤å‰å·²ç»åˆ†æè¿‡ï¼ˆæˆ–åˆšåˆšåˆ†æå®Œï¼‰ï¼Œä½¿ç”¨æŒä¹…åŒ–ç»“æœæ¸²æŸ“ç•Œé¢
        if st.session_state.get('analyzed', False):
            # ä» session_state æ¢å¤
            analyzed_df = st.session_state['analyzed_df']
            weights = st.session_state['analyzed_weights']
            details_list = st.session_state['analyzed_details']
            used_columns = st.session_state['analyzed_used_columns']
            display_results(
                analyzed_df, weights, details_list, used_columns,
                assessment,
                st.session_state.get('custom_factors', None),
                st.session_state.get('correlation_settings', None)
            )
    
  
    with st.expander("ğŸ“– ä½¿ç”¨è¯´æ˜"):
        st.markdown("""
        ### ç³»ç»ŸåŠŸèƒ½
        - **é¢„è®¾æ¨¡å¼**: ä½¿ç”¨ç”µè´¹ã€ç‡ƒæ–™è´¹ã€è¿è¡Œæ—¶é—´ç­‰å¸¸è§æŒ‡æ ‡
        - **è‡ªå®šä¹‰æ¨¡å¼**: å®Œå…¨è‡ªå®šä¹‰è¯„ä¼°è¦ç´ å’Œç›¸å…³æ€§è®¾ç½®
        - **ç†µæƒæ³•æƒé‡è®¡ç®—**: å®¢è§‚ç¡®å®šå„è¯„ä¼°å› å­çš„æƒé‡
        - **æ­£è´Ÿç›¸å…³æ€§å¤„ç†**: æ”¯æŒæ­£ç›¸å…³å’Œè´Ÿç›¸å…³è¦ç´ çš„æƒé‡è®¡ç®—
        
        ### ç›¸å…³æ€§è¯´æ˜
        - **æ­£ç›¸å…³**: æŒ‡æ ‡æ•°å€¼è¶Šå¤§ï¼Œé¢„æœŸç¢³æ’æ”¾è¶Šå¤§ï¼ˆå¦‚ï¼šç”¨ç”µé‡ã€ç‡ƒæ–™è´¹ï¼‰
        - **è´Ÿç›¸å…³**: æŒ‡æ ‡æ•°å€¼è¶Šå¤§ï¼Œé¢„æœŸç¢³æ’æ”¾è¶Šå°ï¼ˆå¦‚ï¼šè®¾å¤‡æ•ˆç‡ã€äº§å“è´¨é‡ï¼‰
        
        ### è‡ªå®šä¹‰æ¨¡å¼CSVæ ¼å¼ç¤ºä¾‹
        ```
        process_name,factor_1,factor_2,factor_3,factor_4
        æµç¨‹A,120.5,78.2,25.1,95.3
        æµç¨‹B,85.7,55.9,15.2,88.7
        ```
        
        ### é¢„è®¾æ¨¡å¼CSVæ ¼å¼ç¤ºä¾‹  
        ```
        process_name,electricity_kwh,electricity_cost,natural_gas_m3,fuel_cost,operation_hours
        æµç¨‹A,120,78,25,75,10
        æµç¨‹B,85,55,15,45,6
        ```
        
        ### å­—ä½“æ–‡ä»¶é…ç½®è¯´æ˜
        ä¸ºäº†åœ¨Streamlit Cloudä¸Šæ­£ç¡®æ˜¾ç¤ºä¸­æ–‡ï¼š
        1. å°† `simhei.ttf` å­—ä½“æ–‡ä»¶æ”¾åœ¨é¡¹ç›®æ ¹ç›®å½•
        2. åœ¨ `requirements.txt` ä¸­æ·»åŠ å¿…è¦çš„ä¾èµ–
        3. ç³»ç»Ÿä¼šè‡ªåŠ¨æ£€æµ‹å¹¶åŠ è½½å­—ä½“æ–‡ä»¶
        
        ### requirements.txt ç¤ºä¾‹
        ```
        streamlit
        pandas
        numpy
        matplotlib
        seaborn
        ```
        """)

if __name__ == "__main__":
    main()




